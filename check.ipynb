{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import random\n",
    "model = YOLO('best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_up(matrix): # заменяет все числа на 1 и 0\n",
    "    \"\"\"\n",
    "    массив, что содержит в себе все цвета каждого пикселя преобразует числа цветов в 1 и нолики (0 - чёрный цвет, а 1 - белый цвет)\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(matrix)\n",
    "    result[matrix > 150] = 1\n",
    "    return result\n",
    "\n",
    "def split_matrix(matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    разделяет список на 49 частей (то есть разделяет весь массив, картинку на матрицу 7 на 7 клеток), после избавляется от крайних столбцов и строк => выводит матрицу 5 на 5\n",
    "    \"\"\"\n",
    "    row_size, col_size = rows // 7, cols // 7\n",
    "    parts = []\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            part = matrix[i * row_size : (i + 1) * row_size, j * col_size : (j + 1) * col_size]\n",
    "            parts.append(part)\n",
    "\n",
    "    central_parts = []\n",
    "    for i in range(1, 6):\n",
    "        for j in range(1, 6):\n",
    "            central_parts.append(parts[i * 7 + j])\n",
    "    \n",
    "    return central_parts\n",
    "\n",
    "def replace_based_on_center(parts):\n",
    "    \"\"\"\n",
    "    округляет каждую часть списка до 1 или 0 на основе цвета центрального пикселя\n",
    "    \"\"\"\n",
    "    replaced_parts = []\n",
    "    for part in parts:\n",
    "        center_pixel = part[len(part) // 2, len(part[0]) // 2]\n",
    "        replaced_part = np.full_like(part, center_pixel)\n",
    "        replaced_parts.append(replaced_part)\n",
    "    \n",
    "    return replaced_parts\n",
    "\n",
    "def combine_parts(rounded_parts):\n",
    "    \"\"\"\n",
    "    сохраняет всё в виде матрицы 5 на 5, где каждая клетка равна либо положительному числу, либо нулю\n",
    "    \"\"\"\n",
    "    combined_matrix = np.zeros((5, 5))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            part_index = i * 5 + j\n",
    "            combined_matrix[i, j] = 1 if np.sum(rounded_parts[part_index]) > 0 else 0\n",
    "    return combined_matrix\n",
    "\n",
    "def read_from_json(filename):\n",
    "    # Открытие файла для чтения\n",
    "    with open(filename, 'r') as json_file:\n",
    "        # Загрузка данных из файла\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def load_json_to_matrices(filename):\n",
    "    \"\"\"\n",
    "    загрузка базы данных в список matrices и преобразование его в словарь numpy\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    matrices = {}\n",
    "    for key, value in data.items():\n",
    "        matrices[key] = np.array(value)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "def compare_matrices(matrix1, matrices_from_json):\n",
    "    \"\"\"\n",
    "    сравнение нашей матрицы с матрицами из базы данных\n",
    "    \"\"\"\n",
    "    for key, matrix2 in matrices_from_json.items():\n",
    "        if np.array_equal(matrix1, matrix2):\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def image_optimization(image):\n",
    "    \"\"\"\n",
    "    Изменяет качество картинки до изображение в 70 на 70 пикселей\n",
    "    \"\"\"\n",
    "    enlarged_image = cv2.resize(image, (70, 70), interpolation=cv2.INTER_CUBIC)\n",
    "    optimized_image_path = 'optimized_image.png'\n",
    "    cv2.imwrite(optimized_image_path, enlarged_image)\n",
    "    return optimized_image_path\n",
    "\n",
    "def main(picture, json_file): \n",
    "    \"\"\"\n",
    "    Финальная функция, что содержит в себе все предыдущие. main возвращает номер карточки и вариант её ответа, если же данная картачка не\n",
    "    совпадает ни с одной из карточек из базы данных, то возвращается None. (Принимает на вход саму картинку и файл с базой данных)\n",
    "    \"\"\"\n",
    "    cb_img = cv2.imread(picture, 0)\n",
    "    cb_img_np = np.array(cb_img)\n",
    "    lines, columns = cb_img.shape\n",
    "    the_converted_image = combine_parts(replace_based_on_center(split_matrix(rounding_up(cb_img_np), lines, columns)))\n",
    "    return compare_matrices(the_converted_image, load_json_to_matrices(json_file))\n",
    "    # Предполагаем, что cb_img_np уже является массивом numpy.ndarray, представляющим изображение в оттенках серого\n",
    "\n",
    "\n",
    "def mainer(cb_img_np, json_file):\n",
    "    \"\"\"\n",
    "    Финальная функция, что содержит в себе все предыдущие. main возвращает номер карточки и вариант её ответа, если же данная картачка не\n",
    "    совпадает ни с одной из карточек из базы данных, то возвращается None. (Принимает на вход массив numpy.ndarray и файл с базой данных)\n",
    "    \"\"\"\n",
    "\n",
    "    cb_img_np = cv2.cvtColor(cb_img_np, cv2.COLOR_BGR2GRAY)\n",
    "    cb_img=image_optimization(cb_img_np)\n",
    "    cb_img = cv2.imread(cb_img, 0)\n",
    "    cb_img_np = np.array(cb_img)\n",
    "    lines, columns = cb_img_np.shape[:2]\n",
    "    the_converted_image = combine_parts(replace_based_on_center(split_matrix(rounding_up(cb_img_np), lines, columns)))\n",
    "    return compare_matrices(the_converted_image, load_json_to_matrices(json_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трансформация карточек (Выравние)\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция вырезки карточек из изображения\n",
    "def crop_images(img, coordinates):\n",
    "    images = []\n",
    "    for coords in coordinates:\n",
    "        left, top, right, bottom = map(int, coords)\n",
    "        cropped_img = img[top-5:bottom+5, left-5:right+5]\n",
    "        images.append(cropped_img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 (no detections), 300.0ms\n",
      "Speed: 5.9ms preprocess, 300.0ms inference, 1421.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "#Получение изображения с карточками в ограничивающей рамке\n",
    "def get_processed_photo(photo):\n",
    "    photo=cv2.imread(photo)\n",
    "    results=model(photo,conf=0.8)\n",
    "    im_array = results[0].plot()\n",
    "    return im_array\n",
    "result_photo=get_processed_photo('fKPZ3p7CjU8.jpg')\n",
    "cv2.imshow('result',result_photo)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение вырезанных карточек без ориентации\n",
    "def save_crop_photos(img,save_dir):\n",
    "    results=model(img,conf=0.8)\n",
    "    results[0].save_crop(save_dir)\n",
    "save_crop_photos(cv2.imread('100.jpg'),'C:/Users/Admin/Downloads/dfdsf/save_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение выраезанных карточек с ориентацией\n",
    "def save_image_with_sequence_number(image, directory, base_name):\n",
    "    # Проверка существования директории, и если её нет, то создание\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Получение списка файлов в директории\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Вычисление номера для нового файла\n",
    "    number = len(files) + 1\n",
    "    \n",
    "    # Составление имени файла с учетом базового имени и номера\n",
    "    file_name = os.path.join(directory, f\"{base_name}{number}.jpg\")\n",
    "    \n",
    "    # Сохранение изображения\n",
    "    cv2.imwrite(file_name, image)\n",
    "    \n",
    "    print(f\"Изображение сохранено как {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отрисовка рамок с подписями ответов\n",
    "def draw_bounding_box(image, box, card_name):\n",
    "    #color = (random.randint(70, 255), random.randint(70, 255), random.randint(70, 255))\n",
    "    color=(0,255,0)\n",
    "    box=[int(num) for num in box]\n",
    "    start_x, start_y, end_x, end_y = box\n",
    "    cv2.rectangle(image, (start_x, start_y), (end_x, end_y), color, 4)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottom_left_corner_of_text = (10, 30)\n",
    "    font_scale = 1\n",
    "    line_type = 0\n",
    "    thickness = 5\n",
    "    cv2.putText(image, card_name, (start_x,start_y-6), font, font_scale, color,thickness)\n",
    "    #cv2.imshow(\"Image with Bounding Box\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Поиск контура карточки\n",
    "def find_largest_contour(image):\n",
    "    # Переводим изображение в оттенки серого\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Применяем пороговую обработку для получения бинарного изображения\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, 0)\n",
    "    # Инвертируем бинарное изображение\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    # Находим контуры на инвертированном бинарном изображении\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4A']\n"
     ]
    }
   ],
   "source": [
    "#Получение результата по фото(Новый)\n",
    "from copy import deepcopy\n",
    "def get_results_photo2(img):\n",
    "    ans=None\n",
    "    answers = []\n",
    "    if img is None:\n",
    "        print(\"Error: The image is empty or not loaded correctly.\")\n",
    "        return answers, img\n",
    "    copy_img=deepcopy(img)\n",
    "    results = model(img, verbose=False,conf=0.7)\n",
    "    boxes = results[0].boxes.xyxy.cpu().tolist()\n",
    "    images = crop_images(img, boxes)\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        if image is None or image.size == 0:\n",
    "            print(f\"Error: The cropped image at index {i} is empty.\")\n",
    "            continue\n",
    "        orig = image\n",
    "        image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "        \n",
    "        edged = cv2.Canny(image, 0,0)\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        \n",
    "        cnts+= find_largest_contour(image)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        screenCnt = None\n",
    "        for c in cnts:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.1 * peri, True)\n",
    "            if len(approx) == 4 and cv2.contourArea(approx)>=20:\n",
    "                screenCnt = approx\n",
    "                if screenCnt is not None:\n",
    "                    warped = four_point_transform(orig, screenCnt.reshape(4, 2))\n",
    "                    try:\n",
    "                        ans=mainer(warped, 'image_database.json')\n",
    "                        draw_bounding_box(copy_img, boxes[i], ans)\n",
    "                    except:\n",
    "                        pass\n",
    "                    if ans not in answers and ans!=None:\n",
    "                        answers.append(ans)\n",
    "                        \n",
    "    return answers, copy_img\n",
    "model = YOLO('best.pt')\n",
    "answers,img=get_results_photo2(cv2.imread(\"HAUvT7Whd84.jpg\"))#Получение итогового изображения и ответов\n",
    "print(answers)\n",
    "height, width = img.shape[:2]\n",
    "    \n",
    "    # Уменьшите изображение в 2 раза\n",
    "img = cv2.resize(img, (width // 2, height // 2), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"Result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, '32B', '36B', '31C', '39B', '40C', '35C', '2A', '1C', '38D', '37C']\n"
     ]
    }
   ],
   "source": [
    "#Получение результата по фото(Старый)\n",
    "def get_results_photo1(img):\n",
    "    answers = []\n",
    "    if img is None:\n",
    "        print(\"Error: The image is empty or not loaded correctly.\")\n",
    "        return answers, img\n",
    "    results = model(img, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().tolist()\n",
    "    images = crop_images(img, boxes)\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        if image is None or image.size == 0:\n",
    "            print(f\"Error: The cropped image at index {i} is empty.\")\n",
    "            continue\n",
    "        orig = image\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        \n",
    "        edged = cv2.Canny(image, 120,255)\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        \n",
    "        cnts+= find_largest_contour(image)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        screenCnt = None\n",
    "        for c in cnts:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "            if len(approx) == 4:\n",
    "                screenCnt = approx\n",
    "                if screenCnt is not None:\n",
    "                    warped = four_point_transform(orig, screenCnt.reshape(4, 2))\n",
    "                    try:\n",
    "                        ans=mainer(warped, 'image_database.json')\n",
    "                    except:pass\n",
    "                    if ans not in answers:\n",
    "                        answers.append(ans)\n",
    "    return answers\n",
    "answers=get_results_photo1(cv2.imread(\"0vUota9j3n0.jpg\"))\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для нахождения карточек на больших фотографиях (Разделение фото на более мелкие и их прогон через нейросеть)\n",
    "import cv2\n",
    "from patched_yolo_infer import MakeCropsDetectThem, CombineDetections\n",
    "def find_hard_cards(img):\n",
    "    element_crops = MakeCropsDetectThem(\n",
    "        image=img,\n",
    "        model_path='best.pt',\n",
    "        segment=False,\n",
    "        shape_x=640,\n",
    "        shape_y=640,\n",
    "        overlap_x=10,\n",
    "        overlap_y=20,\n",
    "        conf=0.3,\n",
    "        iou=0.7,\n",
    "        resize_initial_size=True,\n",
    "    )\n",
    "    result = CombineDetections(element_crops, nms_threshold=0.25, match_metric='IOS')  \n",
    "    boxes=result.filtered_boxes\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для обработки и сохранения видео\n",
    "import cv2\n",
    "def extract_frames(video_path):\n",
    "    # Загрузка видео\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    # Получение параметров видео\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    size = (frame_width, frame_height)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Используйте 'mp4v' для MP4\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Здесь можно вызвать вашу функцию обработки кадра\n",
    "        _,processed_frame = get_results_photo2(frame)\n",
    "        frames.append(processed_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames, fps, size, fourcc\n",
    "\n",
    "def save_video(frames, output_path, fps, size, fourcc):\n",
    "    # Создание объекта VideoWriter\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, size)\n",
    "    \n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "\n",
    "# Пример использования\n",
    "video_path = 'video_20240605_150952.mp4'\n",
    "frames, fps, size, fourcc = extract_frames(video_path)\n",
    "output_path = '9999.mp4'\n",
    "save_video(frames, output_path, fps, size, fourcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#демонстрация работы модели на видео\n",
    "def real_time_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model(frame,verbose=False,conf=0.8)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "real_time_video('video_20240605_150952.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "#демонстрация работы модели + алгоритма распознования карточек на видео \n",
    "def video_detect_card(video_path):\n",
    "    frame_counter=0\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    answers = set()\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            frame_counter += 1\n",
    "            # Display the annotated frame\n",
    "            result,img = get_results_photo2(frame)\n",
    "            cv2.imshow(\"YOLOv8 Inference\", img)\n",
    "            for value in result:\n",
    "                    answers.add(value)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return(answers)\n",
    "\n",
    "print(video_detect_card('video_20240605_150952.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 17 cards, 45.0ms\n",
      "Speed: 784.0ms preprocess, 45.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Демонстрация работы нейросети на видео в реальном времени\n",
    "model = YOLO('best.pt')\n",
    "def Real_time_demonstration():\n",
    "    # Захватываем видеопоток с первой доступной веб-камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Считываем кадр с веб-камеры                     \n",
    "        ret, frame = cap.read()\n",
    "        results = model(frame,verbose=False,conf=0.8)\n",
    "        cv2.imshow('Webcam', results[0].plot())\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Освобождаем ресурсы\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Запускаем функцию для вывода видео с веб-камеры\n",
    "Real_time_demonstration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 1 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 2 is empty.\n",
      "Error: The cropped image at index 3 is empty.\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#Демонстрация работы нейросети + алгоритма распознования карточек в реальном времени Надо переделать (завтра)\n",
    "def Real_time_define():\n",
    "    # Захватываем видеопоток с первой доступной веб-камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_counter=0\n",
    "    answers=set()\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            _,img=get_results_photo2(frame)\n",
    "            cv2.imshow(\"YOLOv8 Inference\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Освобождаем ресурсы\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return answers\n",
    "print(Real_time_define())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
