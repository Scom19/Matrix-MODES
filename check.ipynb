{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "model = YOLO('best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_up(matrix): # заменяет все числа на 1 и 0\n",
    "    \"\"\"\n",
    "    массив, что содержит в себе все цвета каждого пикселя преобразует числа цветов в 1 и нолики (0 - чёрный цвет, а 1 - белый цвет)\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(matrix)\n",
    "    result[matrix > 128] = 1\n",
    "    return result\n",
    "\n",
    "def split_matrix(matrix, rows, cols):\n",
    "    \"\"\"\n",
    "    разделяет список на 25 частей (то есть разделяет весь массив, картинку на матрицу 5 на 5 клеток)\n",
    "    \"\"\"\n",
    "    row_size, col_size = rows // 5, cols // 5\n",
    "    parts = []\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            part = matrix[i * row_size : (i + 1) * row_size, j * col_size : (j + 1) * col_size]\n",
    "            parts.append(part)\n",
    "    return parts\n",
    "\n",
    "def round_to_majority(parts):\n",
    "    \"\"\"\n",
    "    округляет каждую часть списка до 1 или нолика в зависимости от того, какbх сзначений там больше, единиц или ноликов, после чего сохраняет\\n\n",
    "    список в виде матрицы 5 на 5, в котором есть только нули и положительные повторяющиеся цифры\n",
    "    \"\"\"\n",
    "    rounded_parts = []\n",
    "    for part in parts:\n",
    "        count_ones = np.count_nonzero(part)\n",
    "        count_zeros = part.size - count_ones\n",
    "        if count_ones >= count_zeros:\n",
    "            rounded_part = np.ones_like(part)\n",
    "        else:\n",
    "            rounded_part = np.zeros_like(part)\n",
    "        rounded_parts.append(rounded_part)\n",
    "    return rounded_parts\n",
    "\n",
    "def combine_parts(rounded_parts):\n",
    "    \"\"\"\n",
    "    сохраняет всё в виде матрицы 5 на 5, где каждая клетка равна либо положительному числу, либо нулю\n",
    "    \"\"\"\n",
    "    combined_matrix = np.zeros((5, 5))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            part_index = i * 5 + j\n",
    "            combined_matrix[i, j] = np.sum(rounded_parts[part_index])\n",
    "    return combined_matrix\n",
    "\n",
    "def final_rounding(matrix):\n",
    "     \"\"\"\n",
    "     преобразуем наш конечный список из 25 чисел в 0 и единицы, а именно исправляем баг, где числы не равные 0 могут быть больше 1, например 4260 и т.п.\n",
    "     \"\"\"\n",
    "     matrix[matrix > 0] = 1\n",
    "     return matrix\n",
    "\n",
    "def read_from_json(filename):\n",
    "    # Открытие файла для чтения\n",
    "    with open(filename, 'r') as json_file:\n",
    "        # Загрузка данных из файла\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def load_json_to_matrices(filename):\n",
    "    \"\"\"\n",
    "    загрузка базы данных в список matrices и преобразование его в словарь numpy\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    matrices = {}\n",
    "    for key, value in data.items():\n",
    "        matrices[key] = np.array(value)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "def compare_matrices(matrix1, matrices_from_json):\n",
    "    \"\"\"\n",
    "    сравнение нашей матрицы с матрицами из базы данных\n",
    "    \"\"\"\n",
    "    for key, matrix2 in matrices_from_json.items():\n",
    "        if np.array_equal(matrix1, matrix2):\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def mainer(picture, json_file): \n",
    "    \"\"\"\n",
    "    Финальная функция, что содержит в себе все предыдущие. main возвращает номер карточки и вариант её ответа, если же данная картачка не\n",
    "    совпадает ни с одной из карточек из базы данных, то возвращается None. (Принимает на вход саму картинку и файл с базой данных)\n",
    "    \"\"\"\n",
    "    cb_img = picture\n",
    "    cb_img_np = np.array(cb_img)\n",
    "    _, cb_img_np = cv2.threshold(cb_img_np, 127, 255, 0)\n",
    "    lines, columns = cb_img.shape\n",
    "    the_converted_image = final_rounding(combine_parts(round_to_majority(split_matrix(rounding_up(cb_img_np), lines, columns))))\n",
    "    return compare_matrices(the_converted_image, load_json_to_matrices(json_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трансформация карточек\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#поиск \"крайних точек\" карточки\n",
    "def find_largest_contour(image):\n",
    "    # Переводим изображение в оттенки серого\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Применяем пороговую обработку для получения бинарного изображения\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, 0)\n",
    "    # Инвертируем бинарное изображение\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    # Находим контуры на инвертированном бинарном изображении\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Находим наибольший контур\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    extreme_points = [(0, 0), (0, image.shape[0]), (image.shape[1], image.shape[0]),\n",
    "                      (image.shape[1], 0)]  # Изначально углы изображения\n",
    "    min_distances = [np.inf, np.inf, np.inf, np.inf]  # Изначально расстояния до углов\n",
    "    # Перебор всех точек контура для поиска крайних\n",
    "    for point in largest_contour:\n",
    "        x, y = point[0][0], point[0][1]\n",
    "        distances = [x, image.shape[0] - y, image.shape[1] - x, y]\n",
    "        for i in range(4):\n",
    "            if distances[i] < min_distances[i]:\n",
    "                min_distances[i] = distances[i]\n",
    "                extreme_points[i] = (x, y)\n",
    "    return extreme_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция вырезки карточек из изображения\n",
    "def crop_images(img, coordinates):\n",
    "    images = []\n",
    "    # Применяем пороговую обработку для получения бинарного изображения\n",
    "    for coords in coordinates:\n",
    "        left, top, right, bottom = map(int, coords)\n",
    "        cropped_img = img[top:bottom, left:right]\n",
    "        images.append(cropped_img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция поворота карточи на угол angle\n",
    "def rotate_image(image, angle):\n",
    "    # Получаем высоту и ширину изображения\n",
    "    height, width = image.shape[:2]\n",
    "    # Вычисляем центр поворота\n",
    "    center = (width / 2, height / 2)\n",
    "    # Поворачиваем изображение на заданный угол\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "    return rotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 17 cards, 52.0ms\n",
      "Speed: 8.0ms preprocess, 52.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "#Получение изображения с карточками в ограничивающей рамке\n",
    "def get_processed_photo(photo):\n",
    "    photo=cv2.imread(photo)\n",
    "    results=model(photo,conf=0.8)\n",
    "    im_array = results[0].plot()\n",
    "    return im_array\n",
    "result_photo=get_processed_photo('122.jpg')\n",
    "cv2.imshow('result',result_photo)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение вырезанных карточек без ориентации\n",
    "def save_crop_photos(img,save_dir):\n",
    "    results=model(img,conf=0.8)\n",
    "    results[0].save_crop(save_dir)\n",
    "save_crop_photos(cv2.imread('100.jpg'),'C:/Users/Admin/Downloads/dfdsf/save_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 cards, 240.0ms\n",
      "Speed: 6.0ms preprocess, 240.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "['16C', '5C', '10D', '5D', '9D', '4D', '21D', '17D']\n"
     ]
    }
   ],
   "source": [
    "#Вывод варинтов ответа по карточкам из фотографии\n",
    "def get_results_photo(img):\n",
    "    answers=[]\n",
    "    results=model(img)\n",
    "    boxes = results[0].boxes.xyxy.cpu().tolist()\n",
    "    images=crop_images(img,boxes)\n",
    "    for i in range(len(images)):\n",
    "        image=images[i]\n",
    "        image = cv2.copyMakeBorder(image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "        image=rotate_image(image,30)\n",
    "        pts = np.array(find_largest_contour(image), dtype = \"float32\")\n",
    "        warped = four_point_transform(image, pts)\n",
    "        gray_image = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "        count=0\n",
    "        while mainer(gray_image,'image_database.json')==None and count<=2:\n",
    "            image=rotate_image(image,-60)\n",
    "            pts = np.array(find_largest_contour(image), dtype = \"float32\")\n",
    "            warped = four_point_transform(image, pts)\n",
    "            gray_image = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "            count+=1\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        #cv2.imshow(\"Original\", image)\n",
    "        #cv2.imshow(\"Warped\", gray_image)\n",
    "        #cv2.waitKey(0)\n",
    "        answers.append(mainer(gray_image,'image_database.json'))\n",
    "    return answers\n",
    "print(get_results_photo(cv2.imread('96.jpg')))\n",
    "#96-идеал\n",
    "#113-Ошибка\n",
    "#109-ошибка\n",
    "#107-ошибка\n",
    "#100-ошибка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#демонстрация работы модели на видео\n",
    "def real_time_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model(frame,verbose=False,conf=0.8)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "real_time_video('My-video-Дата.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None, '2A', '1D', '1B', '1A', '2D', '2C', '1C', '2B'}\n"
     ]
    }
   ],
   "source": [
    "#демонстрация работы модели + алгоритма распознования карточек на видео\n",
    "def video_detect_card(video_path):\n",
    "    frame_counter=0\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    answers = set()\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model(frame,verbose=False,conf=0.8)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            frame_counter += 1\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "            if frame_counter % 3 == 0:\n",
    "                result = get_results_photo(annotated_frame)\n",
    "                for value in result:\n",
    "                        answers.add(value)\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return(answers)\n",
    "\n",
    "print(video_detect_card('My-video-Дата.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 17 cards, 45.0ms\n",
      "Speed: 784.0ms preprocess, 45.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Демонстрация работы нейросети на видео в реальном времени\n",
    "def Real_time_demonstration():\n",
    "    # Захватываем видеопоток с первой доступной веб-камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Считываем кадр с веб-камеры\n",
    "        ret, frame = cap.read()\n",
    "        results = model(frame,verbose=False,conf=0.8)\n",
    "        cv2.imshow('Webcam', results[0].plot())\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Освобождаем ресурсы\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Запускаем функцию для вывода видео с веб-камеры\n",
    "Real_time_demonstration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None, '3C', '1D', '1B', '1A', '2C', '3D'}\n"
     ]
    }
   ],
   "source": [
    "#Демонстрация работы нейросети + алгоритма распознования карточек в реальном времени\n",
    "def Real_time_define():\n",
    "    # Захватываем видеопоток с первой доступной веб-камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_counter=0\n",
    "    answers=set()\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model(frame,verbose=False,conf=0.8)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            frame_counter += 1\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "            if frame_counter % 3 == 0:\n",
    "                result = get_results_photo(annotated_frame)\n",
    "                for value in result:\n",
    "                        answers.add(value)\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Освобождаем ресурсы\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return answers\n",
    "print(Real_time_define())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 cards, 33.0ms\n",
      "Speed: 4.0ms preprocess, 33.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "['16C', '23C', '10D', None, '4D', None, None, '17D']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from image_recognition import *\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "\n",
    "# Трансформация карточек\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped\n",
    "\n",
    "\n",
    "# поиск \"крайних точек\" карточки\n",
    "def find_largest_contour(image):\n",
    "    # Переводим изображение в оттенки серого\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Применяем пороговую обработку для получения бинарного изображения\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, 0)\n",
    "    # Инвертируем бинарное изображение\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    # Находим контуры на инвертированном бинарном изображении\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Находим наибольший контур\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    extreme_points = [(0, 0), (0, image.shape[0]), (image.shape[1], image.shape[0]),\n",
    "                      (image.shape[1], 0)]  # Изначально углы изображения\n",
    "    min_distances = [np.inf, np.inf, np.inf, np.inf]  # Изначально расстояния до углов\n",
    "    # Перебор всех точек контура для поиска крайних\n",
    "    for point in largest_contour:\n",
    "        x, y = point[0][0], point[0][1]\n",
    "        distances = [x, image.shape[0] - y, image.shape[1] - x, y]\n",
    "        for i in range(4):\n",
    "            if distances[i] < min_distances[i]:\n",
    "                min_distances[i] = distances[i]\n",
    "                extreme_points[i] = (x, y)\n",
    "    return extreme_points\n",
    "\n",
    "\n",
    "# функция вырезки карточек из изображения\n",
    "def crop_images(img, coordinates):\n",
    "    images = []\n",
    "    # Применяем пороговую обработку для получения бинарного изображения\n",
    "    for coords in coordinates:\n",
    "        left, top, right, bottom = map(int, coords)\n",
    "        cropped_img = img[top:bottom, left:right]\n",
    "        images.append(cropped_img)\n",
    "    return images\n",
    "\n",
    "\n",
    "# функция поворота карточи на угол angle\n",
    "def rotate_image(image, angle):\n",
    "    # Получаем высоту и ширину изображения\n",
    "    height, width = image.shape[:2]\n",
    "    # Вычисляем центр поворота\n",
    "    center = (width / 2, height / 2)\n",
    "    # Поворачиваем изображение на заданный угол\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def get_results_photo(img):\n",
    "    answers = []\n",
    "    results = model(img)\n",
    "    boxes = results[0].boxes.xyxy.cpu().tolist()\n",
    "    images = crop_images(img, boxes)\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        image = cv2.copyMakeBorder(image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "        image = rotate_image(image, 30)\n",
    "        pts = np.array(find_largest_contour(image), dtype=\"float32\")\n",
    "        warped = four_point_transform(image, pts)\n",
    "        gray_image = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "        count = 0\n",
    "        while mainer(gray_image, 'image_database.json') == None and count <= 4:\n",
    "            image = rotate_image(image, -15)\n",
    "            pts = np.array(find_largest_contour(image), dtype=\"float32\")\n",
    "            warped = four_point_transform(image, pts)\n",
    "            gray_image = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "            count += 1\n",
    "        answers.append(mainer(gray_image, 'image_database.json'))\n",
    "    return answers\n",
    "print(get_results_photo(cv2.imread('photo_5314671147608038937_y.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
